{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conservative-newspaper",
   "metadata": {},
   "source": [
    "# Read Teledyne RDI Pathfinder PD0s and smash them all into a NetCDF\n",
    "Functions written by Joe Gradone and Eli Hunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continent-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import glob\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import matplotlib,netCDF4\n",
    "import struct\n",
    "import math\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "## To import functions from GitHub repository, make this path the path to where the repo exists locally\n",
    "sys.path.insert(0,'/Users/joegradone/SynologyDrive/Drive/Rutgers/Research/code/GitHub/Glider_ADCP_Real_Time_Processing/')\n",
    "#from glider_ADCP_real_time_processing import read_PD0, qaqc_data, process_data, write_data\n",
    "\n",
    "from glider_ADCP_real_time_processing_EJHCOMMENT import read_PD0\n",
    "\n",
    "rtime=datetime.datetime(2020,1,1,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting time origin\n",
    "rtime=datetime.datetime(2020,1,1,0,0,0)\n",
    "\n",
    "## Set path to data\n",
    "odir='./'\n",
    "#idir = 'C:\\\\work\\\\glideradcp\\\\data\\\\ru33_2020_11_20_dvl\\\\pd0\\\\'\n",
    "#idir ='/home/hunter/Projects/glider/glideradcp/ru33_2020_11_20_dvl/pd0/'\n",
    "#idir='/home/hunter/Projects/glider/Glider_ADCP_Real_Time_Processing/'\n",
    "idir = 'C:\\\\work\\\\glideradcp\\\\stthomas\\\\'\n",
    "\n",
    "## Initializes empty variables, but for more that just the PD0 output\n",
    "time=[]    \n",
    "depth=[] \n",
    "pitch=[]\n",
    "roll=[]\n",
    "heading=[]\n",
    "temp=[]      \n",
    "u1=[]\n",
    "u2=[]\n",
    "u3=[]\n",
    "u4=[] \n",
    "ei1=[]\n",
    "ei2=[]\n",
    "ei3=[]\n",
    "ei4=[] \n",
    "c1=[]\n",
    "c2=[]\n",
    "c3=[]\n",
    "c4=[]  \n",
    "pg1=[]\n",
    "pg2=[]\n",
    "pg3=[]\n",
    "pg4=[]       \n",
    "bins=[]\n",
    "O_ls=[]\n",
    "G_ls=[]          \n",
    "plt.ion()\n",
    "\n",
    "\n",
    "# ## Main function to run through entire processing workflow\n",
    "# def main(argv):\n",
    "#     files=glob.glob(idir+'*.PD0')\n",
    "#     files.sort(key=os.path.getmtime)\n",
    "#     files=files[-3:]#Gets the last files. \n",
    "    \n",
    "#     for file in files:\n",
    "#         read_PD0(file)\n",
    "#         process_data(U=u1,V=u2,H=35,dz=1,u_daverage=0,v_daverage=0)\n",
    "#         write_data(file)  \n",
    "#         plot_data()\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "## Read in binary PD0 file\n",
    "def read_PD0(infile):\n",
    "    global time,depth,pitch,roll,heading,temp,bins, bin1, sec\n",
    "    global u1,u2,u3,u4\n",
    "    global c1,c2,c3,c4\n",
    "    global ei1,ei2,ei3,ei4\n",
    "    global pg1,pg2,pg3,pg4\n",
    "    print('Reading PDO file : '+infile)\n",
    "    \n",
    "    ## Open file and read in binary\n",
    "    f=open(infile,'rb')\n",
    "    dat = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    ## All this does is try to find the byte location of the first ensemble. \n",
    "    ## Usually its the first byte, but it some applications it is not.  \n",
    "    ## It searches for the header ID and source ID (both '0x7f')\n",
    "    ## See Chapter 8 of  PathFinder DVL Guide_Apr20.pdf \n",
    "    for [ind,tmp1] in enumerate(dat):\n",
    "          if hex(dat[ind])=='0x7f' and hex(dat[ind+1]) =='0x7f':                 \n",
    "                  break\n",
    "    \n",
    "    ## This extracts the number of bytes per ensemble. \n",
    "    nbytes=struct.unpack(\"h\",dat[ind+2:ind+4])[0]+2\n",
    "#    print('Finding Ensembles')      \n",
    "\n",
    "\n",
    "    ## Find the starting byte of every ensemble. (Varaible Iens)\n",
    "    ## It goes through every byte and searchs for header ID's and source ID's\n",
    "    ## When one is found, the index is added to the variable Iens \n",
    "    Iens=[] ## Starting byte of each ensemble. \n",
    "    nind=0\n",
    "    n=0\n",
    "    for [ind,tmp1] in enumerate(dat):\n",
    "          if hex(dat[ind])=='0x7f':\n",
    "              n=n+1\n",
    "              nbytes2=struct.unpack(\"h\",dat[ind+2:ind+4])[0]+2  \n",
    "             \n",
    "              startens=ind\n",
    "              tdat=dat[startens:startens+nbytes]\n",
    "              if len(tdat)<nbytes:\n",
    "                   print('breaking')\n",
    "                   break\n",
    "              tmp=tdat[nbytes-2:nbytes]\n",
    "              chksum=struct.unpack(\"<H\",tmp)[0]\n",
    "              if (sum(tdat[:nbytes-2]) & 65535) ==  chksum:\n",
    "                      \n",
    "                   if nbytes == nbytes2:\n",
    "  \n",
    "                       nind=ind\n",
    "                       Iens.append(ind)\n",
    "#               else:\n",
    "#                  print('Bad Checksum')\n",
    "\n",
    "    nens=len(Iens)\n",
    "\n",
    "## nens is number of ensembles, so this chunk is preallocating variables that will\n",
    "## be read in. Is the 100 for the 2-dimensional variables just a \"safe\" number of bins\n",
    "## without knowing exactly how many. There's a better way to do this...\n",
    "    time=np.empty((nens),np.double)    \n",
    "    depth=np.empty((nens),np.double) \n",
    "    pitch=np.empty((nens),np.double) \n",
    "    roll=np.empty((nens),np.double) \n",
    "    heading=np.empty((nens),np.double) \n",
    "    temp=np.empty((nens),np.double)\n",
    "    \n",
    "    u1=np.empty((nens,100),np.double) \n",
    "    u2=np.empty((nens,100),np.double) \n",
    "    u3=np.empty((nens,100),np.double)\n",
    "    u4=np.empty((nens,100),np.double)  \n",
    "    ei1=np.empty((nens,100),np.double) \n",
    "    ei2=np.empty((nens,100),np.double) \n",
    "    ei3=np.empty((nens,100),np.double)\n",
    "    ei4=np.empty((nens,100),np.double)  \n",
    "    c1=np.empty((nens,100),np.double) \n",
    "    c2=np.empty((nens,100),np.double) \n",
    "    c3=np.empty((nens,100),np.double)\n",
    "    c4=np.empty((nens,100),np.double)   \n",
    "    pg1=np.empty((nens,100),np.double) \n",
    "    pg2=np.empty((nens,100),np.double) \n",
    "    pg3=np.empty((nens,100),np.double)\n",
    "    pg4=np.empty((nens,100),np.double)    \n",
    "    xform=np.zeros((4,4),np.double)   \n",
    "    xformR=np.zeros((3,3),np.double)\n",
    "    xformP=np.zeros((3,3),np.double)\n",
    "    xformH=np.zeros((3,3),np.double)\n",
    "\n",
    "    ind=0\n",
    "    eoffset=0\n",
    "#    Iens=Iens[0:nens]\n",
    "\n",
    "## Loop through ensembles and pull out data.\n",
    "## Which bytes correspiond to what variables is detailed in the Pathfinder manual Ch 8. This is standard for PD0s?\n",
    "    for ind2 in Iens:\n",
    "        startens=(ind2)\n",
    "        tdat=dat[startens:startens+nbytes]\n",
    "        # a=buffer(tdat,2,2)\n",
    "        tnbytes=struct.unpack(\"H\",tdat[2:4])[0]+2\n",
    "        # a=buffer(tdat,nbytes-2,2)\n",
    "        chksum=struct.unpack(\"<H\",tdat[nbytes-2:nbytes])[0]\n",
    "\n",
    "        ## In the past binary data was subject to erros (missing bytes)during read/writing/data transfer operations. \n",
    "        ## It is common practive to add a Checksum to the end of the data. \n",
    "        ## i.e. the last 2 bytes of the ensemble represent the \"sum\" of every byte in the ensemble. \n",
    "        ## if they do not match, data was lost in the ensemble. This happens rarely.\n",
    "        if (sum(tdat[:nbytes-2]) & 65535) ==  chksum:\n",
    "              ndtype=struct.unpack(\"b\",tdat[5:6])[0]\n",
    " \n",
    "              offsets=list()\n",
    "              for ind3 in range(ndtype):\n",
    "                   Is=6+ind3*2\n",
    "                   offsets.append(struct.unpack_from(\"h\",tdat[Is:Is+2])[0])        \n",
    "            \n",
    "            ## FIXEDLEADER\n",
    "            ## Number of beams\n",
    "              Is=offsets[0]+8\n",
    "              nbeam=tdat[Is]\n",
    "            ## Number of cells\n",
    "              Is=offsets[0]+9\n",
    "              ncells=tdat[Is]  \n",
    "            ## Cell size\n",
    "              Is=offsets[0]+12\n",
    "              cellsize=struct.unpack(\"H\",tdat[Is:Is+2])[0]        \n",
    "              cellsize=cellsize/100.0       \n",
    "            ## Bin 1 distance in cm --> meters\n",
    "              Is=offsets[0]+32\n",
    "              bin1=struct.unpack(\"H\",tdat[Is:Is+2])[0]    \n",
    "              bin1=bin1/100.0\n",
    "            ## Heading alignment/100 to get degrees    \n",
    "              Is=offsets[0]+26\n",
    "              hdalign=struct.unpack(\"H\",tdat[Is:Is+2])[0]    \n",
    "              hdalign=hdalign/100.0\n",
    "            ## Heading bias/100 to get degrees\n",
    "              Is=offsets[0]+28\n",
    "              hdbias=struct.unpack(\"H\",tdat[Is:Is+2])[0]    \n",
    "              hdbias=hdbias/100.0\n",
    "            \n",
    "              Is=offsets[0]+4\n",
    "              # sysconfig1=bin(tdat[Is])   \n",
    "              sysconfig1=format(tdat[Is], '#010b')[2:]\n",
    "              Is=offsets[0]+5\n",
    "              # sysconfig2=bin(tdat[Is]) \n",
    "              sysconfig2=format(tdat[Is], '#010b')[2:]\n",
    "            \n",
    "            ## Beam angle correction\n",
    "              if sysconfig2[-2:]=='10':\n",
    "                  bmang=30.0\n",
    "              elif sysconfig2[-2:]=='01':\n",
    "                  bmang=20.0\n",
    "              elif sysconfig2[-2:]=='00':\n",
    "                  bmang=15.0\n",
    "              a=1.0/(2.0*np.sin(bmang*np.pi/180.0))\n",
    "              b=1.0/(4.0*np.cos(bmang*np.pi/180.0))\n",
    "              c=1.0\n",
    "              d=a/np.sqrt(2.0)\n",
    "            ## Building transformation matrix for beam to instrument\n",
    "              xform[0,0]=c*a  \n",
    "              xform[0,1]=-c*a\n",
    "              xform[0,2]=0.0\n",
    "              xform[0,3]=0.0  \n",
    "            \n",
    "              xform[1,0]=0.0  \n",
    "              xform[1,1]=0.0\n",
    "              xform[1,2]=-c*a\n",
    "              xform[1,3]=c*a\n",
    "              \n",
    "              xform[2,0]=b  \n",
    "              xform[2,1]=b\n",
    "              xform[2,2]=b\n",
    "              xform[2,3]=b\n",
    "              \n",
    "              xform[3,0]=d  \n",
    "              xform[3,1]=d\n",
    "              xform[3,2]=-d\n",
    "              xform[3,3]=-d\n",
    "\n",
    "              Is=offsets[1]+2\n",
    "              ens=struct.unpack(\"H\",tdat[Is:Is+2])[0]        \n",
    "              \n",
    "              \n",
    "     \n",
    "            ## Read in time data\n",
    "              Is=offsets[1]+4\n",
    "              year=tdat[Is]  \n",
    "        \n",
    "              Is=offsets[1]+5\n",
    "              month=tdat[Is]\n",
    "              Is=offsets[1]+6\n",
    "              day=tdat[Is]\n",
    "              Is=offsets[1]+7\n",
    "              hour=tdat[Is]\n",
    "              Is=offsets[1]+8\n",
    "              minute=tdat[Is]\n",
    "              Is=offsets[1]+9\n",
    "              sec=tdat[Is]\n",
    "              Is=offsets[1]+10\n",
    "              hsec=tdat[Is]\n",
    "\n",
    "              ttime = datetime.datetime(year+2000,month,day,hour,minute,sec,hsec*10)-rtime\n",
    "            ## Read in depth data\n",
    "              Is=offsets[1]+16\n",
    "              tdepth=struct.unpack(\"H\",tdat[Is:Is+2])[0]   \n",
    "            ## Convert depth from decimeters to meters\n",
    "              tdepth=tdepth*0.1\n",
    "            ## Read in temporary heading\n",
    "              Is=offsets[1]+18\n",
    "              theading=struct.unpack(\"H\",tdat[Is:Is+2])[0]     \n",
    "              theading=theading/100.0\n",
    "            ## Read in pitch data\n",
    "              Is=offsets[1]+20\n",
    "              tpitch=struct.unpack(\"h\",tdat[Is:Is+2])[0]        \n",
    "              tpitch=tpitch/100.0 \n",
    "            ## Read in roll data\n",
    "              Is=offsets[1]+22\n",
    "              troll=struct.unpack(\"h\",tdat[Is:Is+2])[0]        \n",
    "              troll=troll/100.0    \n",
    "            ## Read in salinity data\n",
    "              Is=offsets[1]+24\n",
    "              tsalt=struct.unpack(\"h\",tdat[Is:Is+2])[0]\n",
    "            ## Read in temperature data\n",
    "              Is=offsets[1]+26\n",
    "              ttemp=struct.unpack(\"h\",tdat[Is:Is+2])[0]        \n",
    "              ttemp=ttemp/100.0       \n",
    "            ## Read in glider pressure data\n",
    "              Is=offsets[1]+48\n",
    "              tpress=struct.unpack(\"i\",tdat[Is:Is+4])[0]        \n",
    "              tpress=tpress/1000.0       \n",
    "            ## Read in velocity data\n",
    "              Is=offsets[2]+2\n",
    "              fmt = \"<%dh\" % (ncells*4)\n",
    "              uvw=struct.unpack(fmt,tdat[Is:Is+ncells*4*2])\n",
    "              uvw=np.array(uvw,dtype=float)\n",
    "            ## Read in echo intensity data\n",
    "              Is=offsets[3]+2\n",
    "              fmt = \"<%dB\" % (ncells*4)\n",
    "              tEI=struct.unpack(fmt,tdat[Is:Is+ncells*4])\n",
    "              tEI=np.array(tEI)\n",
    "            ## Read in correlation data\n",
    "              Is=offsets[4]+2\n",
    "              fmt = \"<%dB\" % (ncells*4)\n",
    "              tC=struct.unpack(fmt,tdat[Is:Is+ncells*4])\n",
    "              tC=np.array(tC)  \n",
    "            ## Read in percent good data\n",
    "              Is=offsets[5]+2\n",
    "              fmt = \"<%dB\" % (ncells*4)\n",
    "              tPG=struct.unpack(fmt,tdat[Is:Is+ncells*4])\n",
    "              tPG=np.array(tPG)              \n",
    "            ## Reshape velocity, ei, corr, and pg to be 2D based on cells and beams\n",
    "              uvw.shape=(ncells,4)\n",
    "              tEI.shape=(ncells,4)\n",
    "              tC.shape=(ncells,4)\n",
    "              tPG.shape=(ncells,4)\n",
    "            ## Create bins variable based on number of cells and cell size and reference it to distance from sensor based on bin1\n",
    "              bins=(np.arange(0,ncells,1,np.double)*cellsize)+bin1    \n",
    "            ## Read in bottom track data/check if bottom track\n",
    "              LO=len(offsets)\n",
    "              if LO>6:\n",
    "                Is=offsets[6]\n",
    "                tmp1=struct.unpack(\"c\",tdat[Is:Is+1])[0]\n",
    "                Is=offsets[6]+1\n",
    "                tmp2=struct.unpack(\"c\",tdat[Is:Is+1])[0]\n",
    "                if [tmp1+tmp2]==[b'\\x00\\x06']:\n",
    "                    Is=offsets[6]+16\n",
    "                    tr1=struct.unpack(\"H\",tdat[Is:Is+2])[0]       \n",
    "                    Is=offsets[6]+18\n",
    "                    tr2=struct.unpack(\"H\",tdat[Is:Is+2])[0]    \n",
    "                    Is=offsets[6]+20\n",
    "                    tr3=struct.unpack(\"H\",tdat[Is:Is+2])[0]    \n",
    "                    Is=offsets[6]+22\n",
    "                    tr4=struct.unpack(\"H\",tdat[Is:Is+2])[0] \n",
    "                    ## Convert bottom track range to meters\n",
    "                    tr1=tr1/100.0     \n",
    "                    tr2=tr2/100.0     \n",
    "                    tr3=tr3/100.0     \n",
    "                    tr4=tr4/100.0\n",
    "\n",
    "                    \n",
    "                \n",
    "            ## Only set velocity data below detected bottom equal to 0 if the bottom track range is greater than 0\n",
    "                if tr1>0:\n",
    "                    uvw[bins>.85*tr1,0]=float(\"NAN\")\n",
    "                if tr2>0:\n",
    "                    uvw[bins>.85*tr2,1]=float(\"NAN\")\n",
    "                if tr3>0:\n",
    "                    uvw[bins>.85*tr3,2]=float(\"NAN\")\n",
    "                if tr4>0:\n",
    "                    uvw[bins>.85*tr4,3]=float(\"NAN\")\n",
    "              \n",
    "            ## Bin map velocity data based on pitch and roll\n",
    "              uvw=mapdepthcells(uvw,tpitch,troll)\n",
    "            ## This is where we actually build the arrays/vecotrs of the PD0 data. \n",
    "            ## ind is incremented at the end of the code block (ind=ind+1 below)\n",
    "            ## It's how we add data to the variables we initialized earlier.  \n",
    "              time[ind]=ttime.days+ttime.seconds/86400.0\n",
    "                  \n",
    "              depth[ind]=tdepth\n",
    "              pitch[ind]=tpitch\n",
    "              roll[ind]=troll\n",
    "              temp[ind]=ttemp\n",
    "              heading[ind]=theading  \n",
    "              # P=np.arctan(np.tan(tpitch*np.pi/180.0)*np.cos(troll*np.pi/180.0))\n",
    "\n",
    "            ## Correct heading\n",
    "              shead=theading+hdalign\n",
    "            ## Build beam to ENU transformation matrix\n",
    "              CH=np.cos(shead*np.pi/180.0)\n",
    "              SH=np.sin(shead*np.pi/180.0)\n",
    "              CR=np.cos(troll*np.pi/180.0)\n",
    "              SR=np.sin(troll*np.pi/180.0)\n",
    "              CP=np.cos(tpitch*np.pi/180.0)\n",
    "              SP=np.sin(tpitch*np.pi/180.0)\n",
    "              # print(CP)\n",
    "              # CP=np.cos(P)\n",
    "              # print(CP)\n",
    "              # SP=np.sin(P)\n",
    "              \n",
    "              xformH[0,0]=CH  \n",
    "              xformH[0,1]=SH\n",
    "              xformH[0,2]=0.0 \n",
    "              xformH[1,0]=-SH \n",
    "              xformH[1,1]=CH\n",
    "              xformH[1,2]=0.0 \n",
    "              xformH[2,0]=0.0  \n",
    "              xformH[2,1]=0.0\n",
    "              xformH[2,2]=1.0 \n",
    "            \n",
    "              xformR[0,0]=CR  \n",
    "              xformR[0,1]=0.0\n",
    "              xformR[0,2]=SR \n",
    "              xformR[1,0]=0.0 \n",
    "              xformR[1,1]=1.0\n",
    "              xformR[1,2]=0.0 \n",
    "              xformR[2,0]=-SR  \n",
    "              xformR[2,1]=0.0\n",
    "              xformR[2,2]=CR\n",
    "              \n",
    "              xformP[0,0]=1.0  \n",
    "              xformP[0,1]=0.0\n",
    "              xformP[0,2]=0.0 \n",
    "              xformP[1,0]=0.0 \n",
    "              xformP[1,1]=CP\n",
    "              xformP[1,2]=-SP \n",
    "              xformP[2,0]=0.0  \n",
    "              xformP[2,1]=SP\n",
    "              xformP[2,2]=CP\n",
    "              \n",
    "            ## QAQC Data\n",
    "              uvw = qaqc_data(uvw,tC,tEI,tPG)\n",
    "            \n",
    "            ## Convert from beam to ENU velocity\n",
    "              uvw=uvw @ xform.transpose()\n",
    "              terr=uvw[:,3]\n",
    "              tuvw=uvw[:,0:3]\n",
    "              tuvw=tuvw @ xformR.transpose()\n",
    "              tuvw=tuvw @ xformP.transpose()\n",
    "              tuvw=tuvw @ xformH.transpose()\n",
    "            \n",
    "              u1[ind,0:ncells]=tuvw[:,0] ## This is now U velocity\n",
    "              u2[ind,0:ncells]=tuvw[:,1] ## This is now V velocity\n",
    "              u3[ind,0:ncells]=tuvw[:,2] ## This is now W velocity\n",
    "              u4[ind,0:ncells]=terr      ## This is now error velocity\n",
    "              ei1[ind,0:ncells]=tEI[:,0] \n",
    "              ei2[ind,0:ncells]=tEI[:,1]\n",
    "              ei3[ind,0:ncells]=tEI[:,2]\n",
    "              ei4[ind,0:ncells]=tEI[:,3]\n",
    "              c1[ind,0:ncells]=tC[:,0]\n",
    "              c2[ind,0:ncells]=tC[:,1]\n",
    "              c3[ind,0:ncells]=tC[:,2]\n",
    "              c4[ind,0:ncells]=tC[:,3]\n",
    "              pg1[ind,0:ncells]=tPG[:,0]\n",
    "              pg2[ind,0:ncells]=tPG[:,1]\n",
    "              pg3[ind,0:ncells]=tPG[:,2]\n",
    "              pg4[ind,0:ncells]=tPG[:,3]            \n",
    "              \n",
    "              ind=ind+1\n",
    "        else:\n",
    "          #   print 'BAD CHECKSUM'\n",
    "            # eoffset=eoffset+1\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    u1=u1[:,0:ncells]\n",
    "    u2=u2[:,0:ncells]\n",
    "    u3=u3[:,0:ncells]\n",
    "    u4=u4[:,0:ncells]\n",
    "    c1=c1[:,0:ncells]\n",
    "    c2=c2[:,0:ncells]\n",
    "    c3=c3[:,0:ncells]\n",
    "    c4=c4[:,0:ncells]\n",
    "    ei1=ei1[:,0:ncells]\n",
    "    ei2=ei2[:,0:ncells]\n",
    "    ei3=ei3[:,0:ncells]\n",
    "    ei4=ei4[:,0:ncells]\n",
    "    pg1=pg1[:,0:ncells]\n",
    "    pg2=pg2[:,0:ncells]\n",
    "    pg3=pg3[:,0:ncells]\n",
    "    pg4=pg4[:,0:ncells]\n",
    "    \n",
    "\n",
    "\n",
    "def mapdepthcells(uvw,tpitch,troll):\n",
    "    global bins\n",
    " #   print('Mapping depth cells')\n",
    "    brange=bins/np.cos(30*np.pi/180.0)\n",
    "    tuvw=uvw*np.nan\n",
    "    az=90*np.pi/180\n",
    "    elev=-60*np.pi/180\n",
    "    ## This is getting the actuall bin depths.(relative to glider), so we can transform them to \"Level\" bin depths \n",
    "    XYZ1 = sph2cart(az,elev,brange)\n",
    "    \n",
    "   \n",
    "    az=-90*np.pi/180\n",
    "    elev=-60*np.pi/180\n",
    "    XYZ2 = sph2cart(az,elev,brange)\n",
    "    \n",
    "    az=0*np.pi/180\n",
    "    elev=-60*np.pi/180\n",
    "    XYZ3 = sph2cart(az,elev,brange) \n",
    "    \n",
    "    az=180*np.pi/180\n",
    "    elev=-60*np.pi/180\n",
    "    XYZ4= sph2cart(az,elev,brange)\n",
    "#    trot=np.array([[0.9330  , -0.0670 ,  -0.3536],[-0.0670  , 0.9330 ,  -0.3536],[0.3536 ,   0.3536 ,   0.8660]])\n",
    "\n",
    "\n",
    "#    print([tpitch,troll])\n",
    "    rang1=tpitch*np.pi/(180) \n",
    "    rang2=troll*np.pi/(180) \n",
    "    sc=1/np.sqrt(2.0)\n",
    "    ax1=sc*rang1*np.array([-1, 1, 0])\n",
    "    ax2=sc*rang2*np.array([1, 1, 0])\n",
    "    rmx1 = R.from_rotvec(ax1)\n",
    "    rmx2 = R.from_rotvec(ax2)\n",
    "    \n",
    "    rot1=rmx1.as_matrix()    \n",
    "    rot2=rmx2.as_matrix()\n",
    "    rXYZ1=np.concatenate(([XYZ1[0]],[XYZ1[1]],[XYZ1[2]]),axis=0)\n",
    "    r1=rXYZ1.transpose() @ rot1 @ rot2\n",
    "    rXYZ2=np.concatenate(([XYZ2[0]],[XYZ2[1]],[XYZ2[2]]),axis=0)\n",
    "    r2=rXYZ2.transpose() @ rot1  @ rot2\n",
    "    rXYZ3=np.concatenate(([XYZ3[0]],[XYZ3[1]],[XYZ3[2]]),axis=0)\n",
    "    r3=rXYZ3.transpose() @ rot1 @ rot2\n",
    "    rXYZ4=np.concatenate(([XYZ4[0]],[XYZ4[1]],[XYZ4[2]]),axis=0)\n",
    "    r4=rXYZ4.transpose() @ rot1 @ rot2\n",
    "    \n",
    "    # gX=np.arange(-10,10)\n",
    "    # gY=gX*0.0\n",
    "    # g=(gX+1j*gY)*np.exp(1j*45.0*np.pi/180)\n",
    "    # gX=np.real(g)\n",
    "    # gY=np.imag(g)\n",
    "    # gZ=0.0*gX\n",
    "    \n",
    "    \n",
    "    # gDX=bins*0.0\n",
    "    # gDY=bins*0.0\n",
    "    # gDZ=-bins\n",
    "    # tmp=np.concatenate(([gX],[gY],[gZ]),axis=0)\n",
    "    # rg=tmp.transpose() @ rot1 @ rot2\n",
    "    \n",
    "    # tmp=np.concatenate(([gDX],[gDY],[gDZ]),axis=0)\n",
    "    # rDg=tmp.transpose() @ rot1 @ rot2\n",
    "    \n",
    "    # plt.figure(1)\n",
    "    # plt.clf()\n",
    "    # ax = plt.axes(projection='3d')\n",
    "    # ax.plot3D(XYZ1[0],XYZ1[1],XYZ1[2],'r')\n",
    "    # ax.plot3D(r1[:,0],r1[:,1],r1[:,2],'b')\n",
    "\n",
    "    # ax.plot3D(XYZ2[0],XYZ2[1],XYZ2[2],'r')\n",
    "    # ax.plot3D(r2[:,0],r2[:,1],r2[:,2],'b')\n",
    "    # ax.plot3D(XYZ3[0],XYZ3[1],XYZ3[2],'r')\n",
    "    # ax.plot3D(r3[:,0],r3[:,1],r3[:,2],'b')\n",
    "    # ax.plot3D(XYZ4[0],XYZ4[1],XYZ4[2],'r')\n",
    "    # ax.plot3D(r4[:,0],r4[:,1],r4[:,2],'b')\n",
    "    # ax.plot3D(gX,gY,gZ,'k')\n",
    "    # ax.plot3D(rg[:,0],rg[:,1],rg[:,2],'b')\n",
    "    \n",
    "\n",
    "    # ax.plot3D(gDX,gDY,gDZ,'r')\n",
    "    # ax.plot3D(rDg[:,0],rDg[:,1],rDg[:,2],'b')\n",
    "    # plt.grid(True)\n",
    "    \n",
    "    tuvw[:,0]=np.interp(-r1[:,2],bins,uvw[:,0])\n",
    "    tuvw[:,1]=np.interp(-r2[:,2],bins,uvw[:,1])\n",
    "    tuvw[:,2]=np.interp(-r3[:,2],bins,uvw[:,2])\n",
    "    tuvw[:,3]=np.interp(-r4[:,2],bins,uvw[:,3])\n",
    "    # plt.figure(3)\n",
    "    # plt.clf()\n",
    "    # plt.subplot(141)\n",
    "    # plt.plot(uvw[:,0],-bins,'r',marker='o')\n",
    "    # plt.plot(tuvw[:,0],-bins,'r',marker='+')\n",
    "    # plt.grid(True)\n",
    "    # plt.subplot(142)\n",
    "    # plt.plot(uvw[:,1],-bins,'b',marker='o')\n",
    "    # plt.plot(tuvw[:,1],-bins,'b',marker='+')\n",
    "    # plt.grid(True)\n",
    "    # plt.subplot(143)\n",
    "    # plt.plot(uvw[:,2],-bins,'k',marker='o')\n",
    "    # plt.plot(tuvw[:,2],-bins,'k',marker='+')\n",
    "    # plt.grid(True)\n",
    "    # plt.subplot(144)\n",
    "    # plt.plot(uvw[:,3],-bins,'g',marker='o')\n",
    "    # plt.plot(tuvw[:,3],-bins,'g',marker='+')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    \n",
    "    # print(\"Paused\")\n",
    "    # input()\n",
    "    return tuvw\n",
    "\n",
    "def qaqc_data(uvw,tC,tEI,tPG):\n",
    "    #print('PROCESSING DVL DATA')\n",
    "    corr_cut = 50\n",
    "    ei_cut   = 70\n",
    "    pg_cut   = 80\n",
    "    \n",
    "    # Change filled values to NaN\n",
    "    uvw[uvw[:,0] == -32768,0] = float(\"NAN\")\n",
    "    uvw[uvw[:,1] == -32768,1] = float(\"NAN\")\n",
    "    uvw[uvw[:,2] == -32768,2] = float(\"NAN\")\n",
    "    uvw[uvw[:,3] == -32768,3] = float(\"NAN\")\n",
    "    \n",
    "    # Convert from mm/s to m/s\n",
    "    uvw[:,0] = uvw[:,0]/1000\n",
    "    uvw[:,1] = uvw[:,1]/1000\n",
    "    uvw[:,2] = uvw[:,2]/1000\n",
    "    uvw[:,3] = uvw[:,3]/1000    \n",
    "    \n",
    "    ## Filter for bad correlation\n",
    "    uvw[tC[:,0] < corr_cut,0] = float(\"NAN\")\n",
    "    uvw[tC[:,1] < corr_cut,1] = float(\"NAN\")\n",
    "    uvw[tC[:,2] < corr_cut,2] = float(\"NAN\")\n",
    "    uvw[tC[:,3] < corr_cut,3] = float(\"NAN\")\n",
    "    \n",
    "#     ## Filter for bad echo intensity\n",
    "#     uvw[tEI[:,0] < ei_cut,0] = float(\"NAN\")\n",
    "#     uvw[tEI[:,1] < ei_cut,1] = float(\"NAN\")\n",
    "#     uvw[tEI[:,2] < ei_cut,2] = float(\"NAN\")\n",
    "#     uvw[tEI[:,3] < ei_cut,3] = float(\"NAN\")\n",
    "\n",
    "    ## Filter for bad percent good\n",
    "    uvw[tPG[:,0] < pg_cut,0] = float(\"NAN\")\n",
    "    uvw[tPG[:,1] < pg_cut,1] = float(\"NAN\")\n",
    "    uvw[tPG[:,2] < pg_cut,2] = float(\"NAN\")\n",
    "    uvw[tPG[:,3] < pg_cut,3] = float(\"NAN\")\n",
    "    \n",
    "    return(uvw)\n",
    "\n",
    "                        \n",
    "def process_data(U,V,H,dz,u_daverage,v_daverage):\n",
    "    global O_ls, G_ls, bin_new    \n",
    "    \n",
    "    ## Feb-2021 jgradone@marine.rutgers.edu Initial\n",
    "    ## Jul-2021 jgradone@marine.rutgers.edu Updates for constraints\n",
    "    \n",
    "    ## Purpose: Take velocity measurements from glider mounted ADCP and compute\n",
    "    # shear profiles\n",
    "    \n",
    "    ## Outputs:\n",
    "    # O_ls is the ocean velocity profile\n",
    "    # G_ls is the glider velocity profile\n",
    "    # bin_new are the bin centers for the point in the profiles\n",
    "    # C is the constant used in the constraint equation (Not applicable for\n",
    "    # real-time processing)\n",
    "    \n",
    "    ## Inputs:\n",
    "    # dz is desired vertical resolution, should not be smaller than bin length\n",
    "    # H is the max depth of the water column\n",
    "    # U is measured east-west velocities from ADCP\n",
    "    # V is measured north-south velocities from ADCP\n",
    "    # Z is the measurement depths of U and V\n",
    "    # uv_daverage is depth averaged velocity (Set to 0 for real-time)\n",
    "    \n",
    "    ##########################################################################        \n",
    "    # Take difference between bin lengths for bin size [m]\n",
    "    bin_size = np.diff(bins)[0]\n",
    "    bin_num = len(bins)\n",
    "\n",
    "    # This creates a grid of the ACTUAL depths of the ADCP bins by adding the\n",
    "    # depths of the ADCP bins to the actual depth of the instrument\n",
    "    [bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "    bin_depth = bdepth+bbins  \n",
    "    Z = bin_depth\n",
    "\n",
    "    # Set knowns from Equations 19 from Visbeck (2002) page 800\n",
    "    # Maximum number of observations (nd) is given by the number of velocity\n",
    "    # estimates per ping (nbin) times the number of profiles per cast (nt)\n",
    "    nbin = U.shape[0]  # number of programmed ADCP bins per individual profile\n",
    "    nt   = U.shape[1]  # number of individual velocity profiles\n",
    "    nd   = nbin*nt      # G dimension (1) \n",
    "\n",
    "    # Define the edges of the bins\n",
    "    bin_edges = np.arange(0,math.floor(np.max(bin_depth)),dz).tolist()\n",
    "\n",
    "    # Check that each bin has data in it\n",
    "    bin_count = np.empty(len(bin_edges)-1) # Preallocate memory\n",
    "    bin_count[:] = np.NaN\n",
    "\n",
    "    for k in np.arange(len(bin_edges))[:-1]:\n",
    "        # Create index of depth values that fall inside the bin edges\n",
    "        ii = np.where((bin_depth > bin_edges[k]) & (bin_depth < bin_edges[k+1]))\n",
    "        bin_count[k] = len(bin_depth[ii])\n",
    "        ii = []\n",
    "\n",
    "    # Create list of bin centers    \n",
    "    bin_new = [x+dz/2 for x in bin_edges[:-1]]\n",
    "\n",
    "    # Chop off the top of profile if no data\n",
    "    ind = np.argmax(bin_count > 0) # Stops at first index greater than 0\n",
    "    bin_new = bin_new[ind:]        # Removes all bins above first with data\n",
    "    z1 = bin_new[0]                # Depth of center of first bin with data\n",
    "\n",
    "    # Create and populate G\n",
    "    nz = len(bin_new)  # number of ocean velocities desired in output profile\n",
    "    nm = nz + nt       # G dimension (2), number of unknowns\n",
    "    # Let's build the corresponding coefficient matrix G \n",
    "    G = np.zeros((nd,nm))\n",
    "\n",
    "    # Indexing of the G matrix was taken from Todd et al. 2011\n",
    "    for ii in np.arange(nt):           # Number of ADCP profiles per cast\n",
    "        for jj in np.arange(nbin):     # Number of measured bins per profile\n",
    "\n",
    "            # Uctd part of matrix\n",
    "            G[(nbin*(ii-1))+jj,ii] = 1\n",
    "\n",
    "            # This will fill in the Uocean part of the matrix. It loops through\n",
    "            # all Z members and places them in the proper location in the G matrix\n",
    "\n",
    "            # Find the difference between all bin centers and the current Z value        \n",
    "            dx = abs(bin_new-Z[ii,jj])\n",
    "\n",
    "            # Find the minimum of these differences\n",
    "            minx = np.nanmin(dx)\n",
    "\n",
    "            # Finds bin_new index of the first match of Z and bin_new    \n",
    "            idx = np.argmin(dx-minx)\n",
    "\n",
    "            G[(nbin*(ii-1))+jj,nt+idx] = 1\n",
    "            del dx, minx, idx\n",
    "\n",
    "\n",
    "    # Reshape U and V into the format of the d column vector\n",
    "    d_u = np.flip(U.transpose(),axis=0)\n",
    "    d_u = d_u.flatten()\n",
    "    d_v = np.flip(V.transpose(),axis=0)\n",
    "    d_v = d_v.flatten()\n",
    "\n",
    "\n",
    "    ##########################################################################\n",
    "    ## This chunk of code containts the constraints for depth averaged currents\n",
    "    ## which we likely won't be using for the real-time processing\n",
    "\n",
    "    # Need to calculate C (Todd et al. 2017) based on our inputs \n",
    "    # This creates a row that has the same # of columns as G. The elements\n",
    "    # of the row follow the trapezoid rule which is used because of the\n",
    "    # extension of the first bin with data to the surface. The last entry of\n",
    "    # the row corresponds to the max depth reached by the glider, any bins\n",
    "    # below that should have already been removed.\n",
    "\n",
    "    constraint = np.concatenate(([np.zeros(nt)], [z1/2], [z1/2+dz/2], [[dz]*(nz-3)], [dz/2]), axis=None)\n",
    "\n",
    "    # To find C, we use the equation of the norm and set norm=1 because we\n",
    "    # desire unity. The equation requires we take the sum of the squares of the\n",
    "    # entries in constraint.\n",
    "\n",
    "    sqr_constraint = constraint*constraint\n",
    "    sum_sqr_constraint = np.sum(sqr_constraint)\n",
    "\n",
    "    # Then we can solve for the value of C needed to maintain unity \n",
    "\n",
    "    C = H*(1/np.sqrt(sum_sqr_constraint))\n",
    "\n",
    "    # This is where you would add the constraint for the depth averaged\n",
    "    # velocity from Todd et al., (2011/2017)\n",
    "\n",
    "    # OG\n",
    "    du = np.concatenate(([d_u],[C*u_daverage]), axis=None)\n",
    "    dv = np.concatenate(([d_v],[C*v_daverage]), axis=None)\n",
    "\n",
    "    # Build Gstar\n",
    "    # Keep this out because not using depth averaged currents\n",
    "    Gstar = np.vstack((G, (C/H)*constraint))\n",
    "\n",
    "    ##########################################################################\n",
    "\n",
    "    # Build the d matrix\n",
    "    d = list(map(complex,du, dv))\n",
    "\n",
    "    ##### Inversion!\n",
    "    ## If want to do with a sparse matrix sol'n, look at scipy\n",
    "    #Gs = scipy.sparse(Gstar)\n",
    "    Gs = Gstar\n",
    "\n",
    "    ms = np.linalg.solve(np.dot(Gs.conj().transpose(),Gs),Gs.conj().transpose())\n",
    "\n",
    "    ## This is a little clunky but I think the dot product fails because of\n",
    "    ## NaN's in the d vector. So, this code will replace NaN's with 0's just\n",
    "    ## for that calculation    \n",
    "    sol = np.dot(ms,np.where(np.isnan(d),0,d))\n",
    "\n",
    "    O_ls = sol[nt:]   # Ocean velocity\n",
    "    G_ls = sol[0:nt]  # Glider velocity\n",
    "\n",
    "\n",
    "def sph2cart(az,elev,r):\n",
    "    z = r * np.sin(elev)\n",
    "    rcoselev = r * np.cos(elev)\n",
    "    x = rcoselev * np.cos(az)\n",
    "    y = rcoselev * np.sin(az)\n",
    "    return x,y,z;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-stage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pharmaceutical-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f=open(files[0],'rb')\n",
    "# dat = f.read()\n",
    "# f.close()\n",
    "\n",
    "# for [ind,tmp1] in enumerate(dat):\n",
    "#       if hex(dat[ind])=='0x7f' and hex(dat[ind+1]) =='0x7f':\n",
    "\n",
    "#               break\n",
    "# nbytes=struct.unpack(\"h\",dat[ind+2:ind+4])[0]+2\n",
    "# #    print('Finding Ensembles')      \n",
    "\n",
    "# Iens=[]\n",
    "# nind=0\n",
    "# n=0\n",
    "# for [ind,tmp1] in enumerate(dat):\n",
    "#       if hex(dat[ind])=='0x7f' and hex(dat[ind+1]) =='0x7f':\n",
    "#           n=n+1\n",
    "#           nbytes2=struct.unpack(\"h\",dat[ind+2:ind+4])[0]+2  \n",
    "\n",
    "#           startens=ind\n",
    "#           tdat=dat[startens:startens+nbytes]\n",
    "#           if len(tdat)<nbytes:\n",
    "#                print('breaking')\n",
    "#                break\n",
    "#           tmp=tdat[nbytes-2:nbytes]\n",
    "#           chksum=struct.unpack(\"<H\",tmp)[0]\n",
    "#           if (sum(tdat[:nbytes-2]) & 65535) ==  chksum:\n",
    "\n",
    "#                if nbytes == nbytes2:\n",
    "\n",
    "#                    nind=ind\n",
    "#                    Iens.append(ind)\n",
    "# #             else:\n",
    "# #                print('Bad Checksum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daily-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.empty(ind)\n",
    "# for x in np.arange(0,ind):\n",
    "#     if hex(dat[x]) == '0x7f':\n",
    "#         print('Good checksum')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-christmas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "married-gothic",
   "metadata": {},
   "source": [
    "## Some functions to read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "altered-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PDO file : /Users/joegradone/Desktop/RU36/ADCP/vb221539.pd0\n",
      "breaking\n"
     ]
    }
   ],
   "source": [
    "## Test on one file\n",
    "idir = '/Users/joegradone/Desktop/RU36/ADCP/'\n",
    "#idir = idir = '/Users/joegradone/Desktop/20220322_MastersOpOc/Masters_0322/Station_0/'\n",
    "#idir = '/Users/joegradone/Desktop/'\n",
    "\n",
    "\n",
    "files=glob.glob(idir+'*.pd0')\n",
    "files.sort(key=os.path.getmtime)\n",
    "read_PD0(files[0])\n",
    "#read_PD0(files[60]) ## Good example of 2 meter bins to 1000 meters\n",
    "\n",
    "#read_PD0(files[12])  ## last 1 meter bin to ~1000 meters\n",
    "#read_PD0(files[15]) ## 15 is last file with 1 meter bins (500 meter dive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "apart-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joegradone/Desktop/RU36/ADCP/vb281441.pd0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1-0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = pd.to_datetime(time, origin='2020-01-01', unit='D')\n",
    "np.max(np.diff(time2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(time,bins)\n",
    "[bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "#minind= 40\n",
    "#maxind= 240\n",
    "\n",
    "#minind=1100\n",
    "#maxind=1160\n",
    "\n",
    "#minind=2100\n",
    "#maxind=2160\n",
    "\n",
    "minind = 3800\n",
    "maxind = 3850\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.pcolormesh(time[minind:maxind],by[:,minind:maxind],pg1[minind:maxind,:].transpose())\n",
    "plt.plot(time[minind:maxind],depth[minind:maxind],'black',linewidth=3)\n",
    "plt.ylabel('Depth [m]')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='Percent Good')\n",
    "#plt.ylim(655,633)\n",
    "#plt.title('RU36 Pathfinder USVI 2022 Pre-QAQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-defendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(time,bins)\n",
    "[bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "#minind= 40\n",
    "#maxind= 240\n",
    "\n",
    "#minind=1100\n",
    "#maxind=1160\n",
    "\n",
    "#minind=2100\n",
    "#maxind=2160\n",
    "\n",
    "minind = 3800\n",
    "maxind = 3850\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.pcolormesh(time[minind:maxind],by[:,minind:maxind],c1[minind:maxind,:].transpose(),vmin=45,vmax=90)\n",
    "plt.plot(time[minind:maxind],depth[minind:maxind],'black',linewidth=3)\n",
    "plt.ylabel('Depth [m]')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='Correlation')\n",
    "#plt.ylim(655,633)\n",
    "#plt.title('RU36 Pathfinder USVI 2022 Pre-QAQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(time,bins)\n",
    "[bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "\n",
    "#minind= 40\n",
    "#maxind= 240\n",
    "\n",
    "#minind=1100\n",
    "#maxind=1160\n",
    "\n",
    "#minind=2100\n",
    "#maxind=2160\n",
    "\n",
    "minind = 3800\n",
    "maxind = 3850\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.pcolormesh(time[minind:maxind],by[:,minind:maxind],ei1[minind:maxind,:].transpose())\n",
    "plt.plot(time[minind:maxind],depth[minind:maxind],'black',linewidth=3)\n",
    "plt.ylabel('Depth [m]')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='Echo Intensity')\n",
    "#plt.ylim(655,633)\n",
    "#plt.title('RU36 Pathfinder USVI 2022 Pre-QAQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,y]=np.meshgrid(time,bins)\n",
    "[bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "\n",
    "by=bdepth+bbins\n",
    "\n",
    "#minind= 40\n",
    "#maxind= 240\n",
    "\n",
    "minind=1100\n",
    "maxind=1160\n",
    "\n",
    "# minind=2100\n",
    "# maxind=2160\n",
    "\n",
    "#minind = 3800\n",
    "#maxind = 3850\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.pcolormesh(time[minind:maxind],by[:,minind:maxind],u2[minind:maxind,:].transpose(),vmin=-0.5,vmax=0.5)\n",
    "plt.plot(time[minind:maxind],depth[minind:maxind],'black',linewidth=3)\n",
    "plt.ylabel('Depth [m]')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='North-South Velocity [m/s]')\n",
    "#plt.ylim(354,348)\n",
    "#plt.title('RU36 Pathfinder USVI 2022 Pre-QAQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-invention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "                       \n",
    "# def process_data(U,V,H,dz,u_daverage,v_daverage):\n",
    "#     global O_ls, G_ls, bin_new    \n",
    "    \n",
    "#     ## Feb-2021 jgradone@marine.rutgers.edu Initial\n",
    "#     ## Jul-2021 jgradone@marine.rutgers.edu Updates for constraints\n",
    "    \n",
    "#     ## Purpose: Take velocity measurements from glider mounted ADCP and compute\n",
    "#     # shear profiles\n",
    "    \n",
    "#     ## Outputs:\n",
    "#     # O_ls is the ocean velocity profile\n",
    "#     # G_ls is the glider velocity profile\n",
    "#     # bin_new are the bin centers for the point in the profiles\n",
    "#     # C is the constant used in the constraint equation (Not applicable for\n",
    "#     # real-time processing)\n",
    "    \n",
    "#     ## Inputs:\n",
    "#     # dz is desired vertical resolution, should not be smaller than bin length\n",
    "#     # H is the max depth of the water column\n",
    "#     # U is measured east-west velocities from ADCP\n",
    "#     # V is measured north-south velocities from ADCP\n",
    "#     # Z is the measurement depths of U and V\n",
    "#     # uv_daverage is depth averaged velocity (Set to 0 for real-time)\n",
    "    \n",
    "#     ##########################################################################        \n",
    "#     # Take difference between bin lengths for bin size [m]\n",
    "#     bin_size = np.diff(bins)[0]\n",
    "#     bin_num = len(bins)\n",
    "\n",
    "#     # This creates a grid of the ACTUAL depths of the ADCP bins by adding the\n",
    "#     # depths of the ADCP bins to the actual depth of the instrument\n",
    "#     [bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "#     bin_depth = bdepth+bbins  \n",
    "#     Z = bin_depth\n",
    "\n",
    "#     # Set knowns from Equations 19 from Visbeck (2002) page 800\n",
    "#     # Maximum number of observations (nd) is given by the number of velocity\n",
    "#     # estimates per ping (nbin) times the number of profiles per cast (nt)\n",
    "#     nbin = U.shape[0]  # number of programmed ADCP bins per individual profile\n",
    "#     nt   = U.shape[1]  # number of individual velocity profiles\n",
    "#     nd   = nbin*nt      # G dimension (1) \n",
    "\n",
    "#     # Define the edges of the bins\n",
    "#     bin_edges = np.arange(0,math.floor(np.max(bin_depth)),dz).tolist()\n",
    "\n",
    "#     # Check that each bin has data in it\n",
    "#     bin_count = np.empty(len(bin_edges)-1) # Preallocate memory\n",
    "#     bin_count[:] = np.NaN\n",
    "\n",
    "#     for k in np.arange(len(bin_edges))[:-1]:\n",
    "#         # Create index of depth values that fall inside the bin edges\n",
    "#         ii = np.where((bin_depth > bin_edges[k]) & (bin_depth < bin_edges[k+1]))\n",
    "#         bin_count[k] = len(bin_depth[ii])\n",
    "#         ii = []\n",
    "\n",
    "#     # Create list of bin centers    \n",
    "#     bin_new = [x+dz/2 for x in bin_edges[:-1]]\n",
    "\n",
    "#     # Chop off the top of profile if no data\n",
    "#     ind = np.argmax(bin_count > 0) # Stops at first index greater than 0\n",
    "#     bin_new = bin_new[ind:]        # Removes all bins above first with data\n",
    "#     z1 = bin_new[0]                # Depth of center of first bin with data\n",
    "\n",
    "#     # Create and populate G\n",
    "#     nz = len(bin_new)  # number of ocean velocities desired in output profile\n",
    "#     nm = nz + nt       # G dimension (2), number of unknowns\n",
    "#     # Let's build the corresponding coefficient matrix G \n",
    "#     G = np.zeros((nd,nm))\n",
    "\n",
    "#     # Indexing of the G matrix was taken from Todd et al. 2011\n",
    "#     for ii in np.arange(nt):           # Number of ADCP profiles per cast\n",
    "#         for jj in np.arange(nbin):     # Number of measured bins per profile\n",
    "\n",
    "#             if np.isfinite(U[jj,ii]):\n",
    "#                 # Uctd part of matrix\n",
    "#                 G[(nbin*(ii-1))+jj,ii] = 1\n",
    "\n",
    "#                 # This will fill in the Uocean part of the matrix. It loops through\n",
    "#                 # all Z members and places them in the proper location in the G matrix\n",
    "\n",
    "#                 # Find the difference between all bin centers and the current Z value        \n",
    "#                 dx = abs(bin_new-Z[ii,jj])\n",
    "\n",
    "#                 # Find the minimum of these differences\n",
    "#                 minx = np.nanmin(dx)\n",
    "\n",
    "#                 # Finds bin_new index of the first match of Z and bin_new    \n",
    "#                 idx = np.argmin(dx-minx)\n",
    "\n",
    "#                 G[(nbin*(ii-1))+jj,nt+idx] = 1\n",
    "#                 del dx, minx, idx\n",
    "\n",
    "\n",
    "#     # Reshape U and V into the format of the d column vector\n",
    "#     d_u = np.flip(U.transpose(),axis=0)\n",
    "#     d_u = d_u.flatten()\n",
    "#     d_v = np.flip(V.transpose(),axis=0)\n",
    "#     d_v = d_v.flatten()\n",
    "\n",
    "\n",
    "#     ##########################################################################\n",
    "#     ## This chunk of code containts the constraints for depth averaged currents\n",
    "#     ## which we likely won't be using for the real-time processing\n",
    "\n",
    "#     # Need to calculate C (Todd et al. 2017) based on our inputs \n",
    "#     # This creates a row that has the same # of columns as G. The elements\n",
    "#     # of the row follow the trapezoid rule which is used because of the\n",
    "#     # extension of the first bin with data to the surface. The last entry of\n",
    "#     # the row corresponds to the max depth reached by the glider, any bins\n",
    "#     # below that should have already been removed.\n",
    "\n",
    "#     constraint = np.concatenate(([np.zeros(nt)], [z1/2], [z1/2+dz/2], [[dz]*(nz-3)], [dz/2]), axis=None)\n",
    "\n",
    "#     # To find C, we use the equation of the norm and set norm=1 because we\n",
    "#     # desire unity. The equation requires we take the sum of the squares of the\n",
    "#     # entries in constraint.\n",
    "\n",
    "#     sqr_constraint = constraint*constraint\n",
    "#     sum_sqr_constraint = np.sum(sqr_constraint)\n",
    "\n",
    "#     # Then we can solve for the value of C needed to maintain unity \n",
    "\n",
    "#     C = H*(1/np.sqrt(sum_sqr_constraint))\n",
    "\n",
    "#     # This is where you would add the constraint for the depth averaged\n",
    "#     # velocity from Todd et al., (2011/2017)\n",
    "\n",
    "#     # OG\n",
    "#     du = np.concatenate(([d_u],[C*u_daverage]), axis=None)\n",
    "#     dv = np.concatenate(([d_v],[C*v_daverage]), axis=None)\n",
    "\n",
    "#     # Build Gstar\n",
    "#     # Keep this out because not using depth averaged currents\n",
    "#     Gstar = np.vstack((G, (C/H)*constraint))\n",
    "\n",
    "#     ##########################################################################\n",
    "\n",
    "#     # Build the d matrix\n",
    "#     d = list(map(complex,du, dv))\n",
    "\n",
    "#     ##### Inversion!\n",
    "#     ## If want to do with a sparse matrix sol'n, look at scipy\n",
    "#     #Gs = scipy.sparse(Gstar)\n",
    "#     Gs = Gstar\n",
    "\n",
    "#     ms = np.linalg.solve(np.dot(Gs.conj().transpose(),Gs),Gs.conj().transpose())\n",
    "\n",
    "#     ## This is a little clunky but I think the dot product fails because of\n",
    "#     ## NaN's in the d vector. So, this code will replace NaN's with 0's just\n",
    "#     ## for that calculation    \n",
    "#     sol = np.dot(ms,np.where(np.isnan(d),0,d))\n",
    "\n",
    "#     O_ls = sol[nt:]   # Ocean velocity\n",
    "#     G_ls = sol[0:nt]  # Glider velocity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-advocacy",
   "metadata": {},
   "source": [
    "# Inversion Function Edits\n",
    "1) H = math.ceil(np.max(bin_depth)) and not callable in the main function <br>\n",
    "2) bin_edges = np.arange(0,H+dz,dz).tolist() <br>\n",
    "3) Need to make sure velocity input to function is in the correct shape, probably best to assume the function is getting the correct shape and manipulate the variable outside <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U = np.flip(u1.transpose())\n",
    "# V = np.flip(u2.transpose())\n",
    "# u_daverage = 0\n",
    "# v_daverage = 0\n",
    "# dz=5\n",
    "\n",
    "# # Take difference between bin lengths for bin size [m]\n",
    "# bin_size = np.diff(bins)[0]\n",
    "# bin_num = len(bins)\n",
    "\n",
    "# # This creates a grid of the ACTUAL depths of the ADCP bins by adding the\n",
    "# # depths of the ADCP bins to the actual depth of the instrument\n",
    "# [bdepth,bbins]=np.meshgrid(depth,bins)\n",
    "# bin_depth = bdepth+bbins  \n",
    "# H = math.ceil(np.max(bin_depth)) # Max sampling depth\n",
    "\n",
    "# # Define the edges of the bins\n",
    "# bin_edges = np.arange(0,H+dz,dz).tolist()\n",
    "\n",
    "# # Check that each bin has data in it\n",
    "# bin_count = np.empty(len(bin_edges)-1) # Preallocate memory\n",
    "# bin_count[:] = np.NaN\n",
    "\n",
    "# for k in np.arange(len(bin_edges))[:-1]:\n",
    "#     # Create index of depth values that fall inside the bin edges\n",
    "#     ii = np.where((bin_depth > bin_edges[k]) & (bin_depth < bin_edges[k+1]))\n",
    "#     bin_count[k] = len(bin_depth[ii])\n",
    "#     ii = []\n",
    "\n",
    "# ## Create list of bin centers    \n",
    "# bin_new = [x+dz/2 for x in bin_edges[:-1]]\n",
    "\n",
    "# ## If there's no data at the top of the profile, chop off the top!\n",
    "# ind = np.argmax(bin_count > 0) # Stops at first index greater than 0\n",
    "# bin_new = bin_new[ind:]        # Removes all bins above first with data\n",
    "# z1 = bin_new[0]                # Depth of center of first bin with data\n",
    "\n",
    "# ## Create and populate G per Visbeck (2002) page 800\n",
    "# nbin = U.shape[0]        # number of programmed ADCP bins\n",
    "# nt   = U.shape[1]        # number of individual velocity pings\n",
    "# nd   = nbin*nt           # G dimension (1) \n",
    "# nz   = len(bin_new)      # number of ocean velocities desired in output profile\n",
    "# nm   = nz + nt           # G dimension (2), number of unknowns\n",
    "# G    = np.zeros((nd,nm)) # Build the corresponding coefficient matrix G \n",
    "\n",
    "# # Indexing of the G matrix was taken from Todd et al. 2011\n",
    "# for ii in np.arange(nt):        # Loop through individual pings\n",
    "#     for jj in np.arange(nbin):  # Loop through individual bins\n",
    "\n",
    "#         if np.isfinite(U[jj,ii]):\n",
    "#             # Uctd part of matrix\n",
    "#             G[(nbin*ii)+jj,ii] = -1\n",
    "            \n",
    "#             # This will fill in the Uocean part of the matrix. It loops through\n",
    "#             # all Z members and places them in the proper location in the G matrix\n",
    "\n",
    "#             # Find the difference between all bin centers and the current Z value        \n",
    "#             dx = abs(bin_new-bin_depth[jj,ii])\n",
    "\n",
    "#             # Find the minimum of these differences\n",
    "#             minx = np.nanmin(dx)\n",
    "\n",
    "#             # Finds bin_new index of the first match of Z and bin_new    \n",
    "#             k = np.argmin(dx-minx)\n",
    "\n",
    "#             G[(nbin*(ii))+jj,nt+k] = 1\n",
    "#             del dx, minx, k\n",
    "\n",
    "\n",
    "# # Reshape U and V into the format of the d column vector\n",
    "# d_u = U.flatten()\n",
    "# d_v = V.flatten()\n",
    "\n",
    "# # Build the d matrix\n",
    "# d = list(map(complex,d_u, d_v))\n",
    "\n",
    "\n",
    "# # Import required package\n",
    "# import numpy as np\n",
    "# from scipy.sparse import csr_matrix\n",
    "  \n",
    "# # Creating a 3 * 4 sparse matrix\n",
    "# Gstar = csr_matrix(G).toarray()\n",
    "\n",
    "# sol = np.linalg.lstsq(Gstar,d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-muslim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(U=u1,V=u2,H=1000,dz=10,u_daverage=0,v_daverage=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(np.real(O_ls),bin_new,label='E-W Velocity',linewidth=3)\n",
    "plt.plot(np.imag(O_ls),bin_new,label='N-S Velocity',linewidth=3)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-kitty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
